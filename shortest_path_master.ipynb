{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['vstack', 'plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "評価語が一番距離の短いところにあるということを証明するためのコード\n",
    "\"\"\"\n",
    "from filer2.filer2 import Filer\n",
    "from library.submodular import SubModular, Vector\n",
    "import collections\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine, sqeuclidean\n",
    "from scipy.sparse import csr_matrix, vstack, lil_matrix\n",
    "import matplotlib.pylab as plt\n",
    "% pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ファイルの読み込み\n",
    "list_sentence = Filer.readtsv('./files/classifiedfile/type11/bigram/bigram/classified-1238_1.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SM = SubModular(list_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = SM._cal_matrix_path_out(inverse_flag=False, weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_element = matrix.max()\n",
    "dict_node_score = {}\n",
    "for i, node in enumerate(SM._list_node):\n",
    "    list_tmp = [num if num != 0 else max_element for num in matrix.getcol(i).toarray().reshape((1,len(SM._list_node)))[0]]\n",
    "    dict_node_score[node] = np.sum(list_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverseの場合(ない場合はmax_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "利用 3461.66666667\n",
      "朝食 3494.66666667\n",
      "良い 3518.66666667\n",
      "満足 3582.66666667\n",
      "食事 3587.16666667\n",
      "美味しい 3609.83333333\n",
      "ホテル 3640.16666667\n",
      "和食 3641.33333333\n",
      "子供 3644.66666667\n",
      "おいしい 3653.66666667\n",
      "残念 3670.66666667\n",
      "部屋 3678.66666667\n",
      "料理 3685.16666667\n",
      "種類 3694.16666667\n",
      "レストラン 3697.66666667\n",
      "ない 3698.41666667\n",
      "品数 3710.66666667\n",
      "中華 3711.66666667\n",
      "洋食 3728.66666667\n",
      "いい 3730.66666667\n"
     ]
    }
   ],
   "source": [
    "for row in sorted(dict_node_score.items(), key=lambda x:x[1])[0:20]:\n",
    "    print row[0], row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverseじゃない場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "利用 178909.0\n",
      "朝食 181082.0\n",
      "良い 181424.0\n",
      "満足 185276.0\n",
      "食事 186020.0\n",
      "ホテル 186420.0\n",
      "子供 187115.0\n",
      "美味しい 188257.0\n",
      "和食 188379.0\n",
      "部屋 188751.0\n",
      "料理 188960.0\n",
      "種類 189762.0\n",
      "おいしい 190024.0\n",
      "レストラン 191043.0\n",
      "中華 191463.0\n",
      "いい 191599.0\n",
      "ない 191729.0\n",
      "残念 192557.0\n",
      "洋食 192869.0\n",
      "夜食 192888.0\n"
     ]
    }
   ],
   "source": [
    "for row in sorted(dict_node_score.items(), key=lambda x:x[1])[0:20]:\n",
    "    print row[0], row[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分散表現を利用した場合の対比実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_word_vec = Filer.readtsv('./files/list_word_vec_s300_w5_m0.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_word_vec = {row[0]: np.array(row[1:], dtype=np.float32) for row in list_word_vec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\\xe6\\xb8\\x85\\xe6\\xbd\\x94\\xe6\\x84\\x9f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d6e0969754bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcos_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcal_matrix_cos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_list_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_word_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ikegami/documents/submodular/library/submodular.py\u001b[0m in \u001b[0;36mcal_matrix_cos\u001b[1;34m(list_word, dict_word_vec)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m                 \u001b[0mcos_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_word_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_word_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcos_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\xe6\\xb8\\x85\\xe6\\xbd\\x94\\xe6\\x84\\x9f'"
     ]
    }
   ],
   "source": [
    "cos_matrix = Vector.cal_matrix_cos(SM._list_node, dict_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_matrix_cos(list_word, dict_word_vec):\n",
    "        \"\"\"\n",
    "        cosine類似度で単語間の距離を計算\n",
    "        list_word: 単語のリスト\n",
    "        dict_word_vec: 単語がkey, 分散表現がvalueのdict\n",
    "        return: cos_matrix: 各単語間の類似度を計算したmatrix\n",
    "        \"\"\"\n",
    "        cos_matrix = np.zeros((len(list_word), len(list_word)))\n",
    "        for i, word1 in enumerate(list_word):\n",
    "            for j, word2 in enumerate(list_word):\n",
    "                try:\n",
    "                    cos_matrix[i][j] = cosine(dict_word_vec[word1], dict_word_vec[word2])\n",
    "                except KeyError:\n",
    "                    cos_matrix[i][j] = 1.0\n",
    "                \n",
    "        return cos_matrix\n",
    "    \n",
    "def cal_matrix_euc(list_word, dict_word_vec):\n",
    "        \"\"\"\n",
    "        cosine類似度で単語間の距離を計算\n",
    "        list_word: 単語のリスト\n",
    "        dict_word_vec: 単語がkey, 分散表現がvalueのdict\n",
    "        return: cos_matrix: 各単語間の類似度を計算したmatrix\n",
    "        \"\"\"\n",
    "        euc_matrix = np.zeros((len(list_word), len(list_word)))\n",
    "        for i, word1 in enumerate(list_word):\n",
    "            for j, word2 in enumerate(list_word):\n",
    "                try:\n",
    "                    euc_matrix[i][j] = sqeuclidean(dict_word_vec[word1], dict_word_vec[word2])\n",
    "                except KeyError:\n",
    "                    euc_matrix[i][j] = 0\n",
    "                \n",
    "        return euc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cos_matrix = cal_matrix_cos(SM._list_node, dict_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_word_cos = {}\n",
    "for i, word in enumerate(SM._list_node):\n",
    "    dict_word_cos[word] = np.sum(cos_matrix[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パスタ 615.340516754\n",
      "洋食 616.83838946\n",
      "デザート 617.829620908\n",
      "サラダ 618.911096303\n",
      "パンケーキ 619.00788399\n",
      "おかず 619.077499042\n",
      "肉じゃが 620.339993231\n",
      "和食 620.375014022\n",
      "スープ 620.974471616\n",
      "グラタン 621.439388853\n",
      "パン 622.015694905\n",
      "ハンバーグ 622.237370199\n",
      "おにぎり 622.504758143\n",
      "ソーセージ 623.301121443\n",
      "ハム 623.602245766\n",
      "おひたし 623.77991601\n",
      "軽食 624.164532091\n",
      "焼き魚 624.183429758\n",
      "煮物 624.867371563\n",
      "バイキング 624.870031386\n"
     ]
    }
   ],
   "source": [
    "for row in sorted(dict_word_cos.items(), key=lambda x:x[1])[0:20]:\n",
    "    print row[0], row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "euc_matrix = cal_matrix_euc(SM._list_node, dict_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_element = np.max(euc_matrix)\n",
    "dict_word_euc = {}\n",
    "for i, word in enumerate(SM._list_node):\n",
    "    list_tmp = [num if num != 0 else max_element for num in euc_matrix[i]]\n",
    "    dict_word_euc[word] = np.sum(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クロージング 682869.43913\n",
      "サラダ・フルーツ・ゼリー・ポテトフライ・パン 683094.385872\n",
      "煜実 683334.036506\n",
      "メープルパイ 683368.750769\n",
      "ンテンテラスホテル 683523.533618\n",
      "モーニングビッフェ 683582.601454\n",
      "メニューバリエ 683723.280411\n",
      "IKSPIARI 683789.084124\n",
      "ドリンクバー 683829.325918\n",
      "グレンサンク 683886.057427\n",
      "ぁっておもったがおいしくてよかったです 683949.267859\n",
      "PowerofMusic 684823.985801\n",
      "ーム 685321.958371\n",
      "ディズニーホテル 686402.328916\n",
      "グランサンク 687113.481767\n",
      "メープル 687389.729124\n",
      "() 687597.078313\n",
      "ブローニュ 688457.916201\n",
      "KIDS 688633.332852\n",
      "ドリア 689339.422661\n"
     ]
    }
   ],
   "source": [
    "for row in sorted(dict_word_euc.items(), key=lambda x:x[1])[0:20]:\n",
    "    print row[0], row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 修正貪欲法のコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cal_cost(list_c_word, distance_matrix, scale):\n",
    "    \"\"\"\n",
    "    コスト１回分の計算\n",
    "    \"\"\"\n",
    "    # 単語をidに変換\n",
    "    list_c_id = sorted([dict_word_id[word] for word in list_c_word])\n",
    "    dm = distance_matrix[:,list_c_id]\n",
    "    f_C = 0.0\n",
    "    for row in dm:\n",
    "        if scale == 0:\n",
    "            f_C -= np.exp(np.amin(row))\n",
    "        elif scale == 1:\n",
    "            f_C -= np.amin(row)\n",
    "        else:\n",
    "            f_C -= np.log(np.amin(row))\n",
    "    return f_C\n",
    "\n",
    "def greedy_1(list_C, list_id_document, distance_matrix, r=1, scale=0):\n",
    "    \"\"\"\n",
    "    修正貪欲法のone loopのためのコード\n",
    "    list_C: 要約文書の集合\n",
    "    list_document: 追加する文書候補の集合\n",
    "    distance_matrix: 各ノード間の距離, W * V\n",
    "    r: コストに追加するハイパーパラメータ\n",
    "    scale: scale関数、0: e^x, 1: x, 2: ln_x\n",
    "    \"\"\"\n",
    "    # 現在のコストを計算\n",
    "    \n",
    "    # 一番初めの時\n",
    "    if len(list_C) == 0:\n",
    "        list_id_score = []\n",
    "        for doc_id, document in list_id_document:\n",
    "            list_c_word = sorted(list(set([word for word in document])))\n",
    "            f_C = cal_cost(list_c_word, distance_matrix, scale)\n",
    "            list_id_score.append([[doc_id, document], f_C])\n",
    "        doc, _ = sorted(list_id_score, key=lambda x:x[1], reverse=True)[0]\n",
    "        return doc\n",
    "    else:\n",
    "        # 単語のuniqueなリストを作成、単語をidに変換\n",
    "        list_c_word = sorted(list(set([word for row in list_C for word in row[1]])))\n",
    "        # f_C: 現在のコストの計算\n",
    "        f_C = cal_cost(list_c_word, distance_matrix, scale)\n",
    "        print f_C\n",
    "        # 文書を１つずつ追加した時のコストの増分を計算\n",
    "        list_id_score = []\n",
    "        for doc_id, document in list_id_document:\n",
    "            # 文章の追加\n",
    "            list_c_word_s = list(set(list_c_word + document))\n",
    "            # コストの計算\n",
    "            f_C_s = cal_cost(list_c_word_s, distance_matrix, scale)\n",
    "            # スコアの増分を計算\n",
    "            delta = (f_C_s - f_C)/(np.power(len(document), r))\n",
    "            list_id_score.append([[doc_id, document], delta])\n",
    "        # スコアの増分が一番大きかったdocを返す\n",
    "        doc, _ = sorted(list_id_score, key=lambda x:x[1], reverse=True)[0]\n",
    "        return doc\n",
    "\n",
    "def greedy(list_id_document, matrix, num_s = 5, r=1, scale=0):\n",
    "    \"\"\"\n",
    "    修正貪欲法で文章の抽出を行うための関数\n",
    "    list_id_document: 文idとbag of wordsが記録されたリスト\n",
    "    matrix: ノード間の距離を記録したmatrix, V * V, numpy_array\n",
    "    num_s: 抜き出したい文章数\n",
    "    r: 文の長さに対するコスト\n",
    "    scale: scale関数として何を使うか、0: e^x, 1: x, 2: ln_x\n",
    "    \"\"\"\n",
    "    # matrixをdistance_matrixに変換\n",
    "    list_row = [matrix[dict_word_id[word]] for row in list_id_document for word in row[1]]\n",
    "    distance_matrix = np.vstack(list_row)\n",
    "    # 要約文章の集合\n",
    "    list_C = []\n",
    "    while len(list_C) < num_s:\n",
    "        doc_id, doc = greedy_1(list_C=list_C,\n",
    "                               list_id_document=list_id_document,\n",
    "                               distance_matrix=distance_matrix,\n",
    "                               r=r, scale=scale)\n",
    "        list_C.append([doc_id, doc])\n",
    "        list_id_document.remove([doc_id, doc])\n",
    "    return list_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ファイルの読み込み\n",
    "list_sentence = Filer.readtsv('./files/classifiedfile/type11/bigram/morpho/classified-1238_0.tsv')\n",
    "SM = SubModular(list_sentence)\n",
    "matrix = SM._cal_matrix_path_out(inverse_flag=True, weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_element = matrix.max()\n",
    "matrix = matrix.toarray()\n",
    "matrix[matrix==0] = max_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_id_document = [[i, row] for i, row in enumerate(list_sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1715087234.98\n",
      "-1661770365.71\n",
      "-1626225133.08\n",
      "-1608452917.47\n",
      "-1599557255.81\n",
      "-1581774436.96\n",
      "-1546218964.19\n",
      "-1537332715.18\n",
      "-1510674288.49\n"
     ]
    }
   ],
   "source": [
    "dict_word_id = SM._dict_word_id\n",
    "list_C = greedy(list_id_document, matrix, num_s = 10, r=1, scale=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = Filer.readtxt('./files/classifiedfile/type11/bigram/sentence/classified-1238_0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "少し残念でしたのは修学旅行生の宿泊により騒音で体調を崩しかけてしまった事ですが、スタッフの方々のお心遣いで事なきを得ました\n",
      "当日その場では、金のことでグダグダ言いたくないし、ましてや楽しみにして来ているのに、嫌らしいから言わなかったけど、足下見過ぎ\n",
      "コンセントの線にゴムテープが巻きついていたので、接触不良なのでしょう\n",
      "駐車券とクレジットカードのかうんとされた時間で３０分以上もかかっているので、途中交代していただきたかったです\n",
      "しっかり説明して欲しかったです\n",
      "自分の住んでいるところ(愛知県)は、ほとんどがタダなのでちょっと意外でした\n",
      "ホテルスタッフの方も親切丁寧な接客でしたし、荷物を運んでくださった方がとても楽しい方で短い時間でしたが楽しませていただきました\n",
      "12時チェックアウトが有り難かったです\n",
      "　チックインして　お昼寝をしましたが　この猛暑で　西日が暑かった\n",
      "連休にお邪魔しました\n"
     ]
    }
   ],
   "source": [
    "for row in list_C:\n",
    "    print sentences[row[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
