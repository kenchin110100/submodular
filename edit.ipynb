{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "ファイルの編集を色々とするためのファイル\n",
    "\"\"\"\n",
    "from filer2.filer2 import Filer\n",
    "import numpy as np\n",
    "import glob\n",
    "import collections\n",
    "import re\n",
    "import MeCab\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 関数の定義\n",
    "mecab = MeCab.Tagger('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "\n",
    "def morpho(sentence):\n",
    "    res = mecab.parseToNode(sentence)\n",
    "    list_words = []\n",
    "    while res:\n",
    "        features = res.feature.split(\",\")\n",
    "        if (features[0] == \"名詞\" and features[1] in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"]) or features[0] == \"形容詞\":\n",
    "            if features[6] == \"*\":\n",
    "                if res.surface != '':\n",
    "                    list_words.append(res.surface)\n",
    "            else:\n",
    "                if features[6] != '':\n",
    "                    list_words.append(features[6])\n",
    "        res = res.next\n",
    "    return list_words\n",
    "\n",
    "def morpho1(sentence):\n",
    "    res = mecab.parseToNode(sentence)\n",
    "    list_words = []\n",
    "    while res:\n",
    "        features = res.feature.split(\",\")\n",
    "        if features[0] != \"記号\":\n",
    "            if features[6] == \"*\":\n",
    "                if res.surface != '':\n",
    "                    list_words.append(res.surface)\n",
    "            else:\n",
    "                if features[6] != '':\n",
    "                    list_words.append(features[6])\n",
    "        res = res.next\n",
    "    return list_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体のコーパスを施設別に集計する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_filepath = glob.glob('../topic_model/files/rakuten_corpus/rakuten_corpus_master/txtfile/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "list_file = [Filer.readtxt(path)  for path in list_filepath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# タブで区切る\n",
    "list_file = [[sentence.split('\\t') for sentence in row] for row in list_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ホテル番号別に集計\n",
    "dict_hotel_sentence = collections.defaultdict(list)\n",
    "for row in list_file:\n",
    "    for sen in row:\n",
    "        dict_hotel_sentence[sen[0]].append(sen[1] + '\\t' + sen[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# review数が100件未満のホテルは除外して保存する\n",
    "for key, value in dict_hotel_sentence.items():\n",
    "    if len(value) >= 100:\n",
    "        Filer.writetxt(value, '../files/txtfile/review-'+key+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数を集計\n",
    "dict_count = {key: len(value) for key, value in dict_hotel_sentence.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 施設名と番号を合わせる\n",
    "list_name = Filer.readtxt('../files/travel03_hotelMaster_20160304.txt')\n",
    "list_name = [sen.split('\\t') for sen in list_name]\n",
    "dict_num_name = {row[0]: row[1] for row in list_name if len(row) == 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 年別にレビュー数を集計\n",
    "dict_counter = {}\n",
    "for key, value in dict_hotel_sentence.items():\n",
    "    dict_counter_tmp = collections.defaultdict(int)\n",
    "    for sen in value:\n",
    "        dict_counter_tmp[sen[0:4]] += 1\n",
    "    dict_counter[key] = dict_counter_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'2001': 3,\n",
       "             '2002': 6,\n",
       "             '2003': 17,\n",
       "             '2004': 6,\n",
       "             '2005': 54,\n",
       "             '2006': 288,\n",
       "             '2007': 96,\n",
       "             '2008': 42,\n",
       "             '2009': 38,\n",
       "             '2010': 31,\n",
       "             '2011': 11})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_count['9680']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 施設番号、施設名、レビュー数のファイルを作成する\n",
    "list_master = [['施設番号', '施設名', 'レビュー数',\n",
    "                '1999', '2000', '2001', '2002',\n",
    "                '2003', '2004', '2005', '2006',\n",
    "                '2007', '2008', '2009', '2010',\n",
    "                '2011']]\n",
    "for key, value in sorted(dict_count.items(), key=lambda x:x[1], reverse=True):\n",
    "    if key in dict_num_name:\n",
    "        list_master.append([key, dict_num_name[key], value, dict_counter[key]['1999'],\n",
    "                            dict_counter[key]['2000'], dict_counter[key]['2001'], dict_counter[key]['2002'],\n",
    "                            dict_counter[key]['2003'], dict_counter[key]['2004'], dict_counter[key]['2005'],\n",
    "                            dict_counter[key]['2006'], dict_counter[key]['2007'], dict_counter[key]['2008'],\n",
    "                            dict_counter[key]['2009'], dict_counter[key]['2010'], dict_counter[key]['2011']])\n",
    "    else:\n",
    "        list_master.append([key, '', value, dict_counter[key]['1999'],\n",
    "                            dict_counter[key]['2000'], dict_counter[key]['2001'], dict_counter[key]['2002'],\n",
    "                            dict_counter[key]['2003'], dict_counter[key]['2004'], dict_counter[key]['2005'],\n",
    "                            dict_counter[key]['2006'], dict_counter[key]['2007'], dict_counter[key]['2008'],\n",
    "                            dict_counter[key]['2009'], dict_counter[key]['2010'], dict_counter[key]['2011']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csvfileとして保存\n",
    "Filer.writecsv(list_master, '../files/txtfile/master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析対象とするホテルのみを取り出して、sentenceごとのファイルにする\n",
    "* 51637：アパホテル＆リゾート＜東京ベイ幕張＞\n",
    "* 1238：オリエンタルホテル東京ベイ\n",
    "* 53171：加賀の湧泉　ドーミーイン金沢\n",
    "* 19191：新横浜プリンスホテル\n",
    "* 76887：ホテルモントレ　グラスミア大阪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_filepath = ['../files/txtfile/review-51637.txt',\n",
    "                 '../files/txtfile/review-1238.txt',\n",
    "                 '../files/txtfile/review-53171.txt',\n",
    "                 '../files/txtfile/review-19191.txt',\n",
    "                 '../files/txtfile/review-76887.txt',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2010年、2011年の文章のみを取得\n",
    "list_review_rev = []\n",
    "for path in list_filepath:\n",
    "    list_review = Filer.readtxt(path)\n",
    "    list_tmp = []\n",
    "    for review in list_review:\n",
    "        if review[0:4] == '2010' or review[0:4] == '2011':\n",
    "            list_tmp.append(review.split('\\t')[1])\n",
    "    list_review_rev.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#【ご利用の宿泊プラン】~を削除\n",
    "pattern = r'【ご利用の宿泊プラン】.+$'\n",
    "list_review_rev1 = []\n",
    "for row in list_review_rev:\n",
    "    list_tmp = []\n",
    "    for sentence in row:\n",
    "        list_tmp.append(re.sub(pattern, '', sentence))\n",
    "    list_review_rev1.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sentenceに変更、その際、ユーザー番号を頭に振る\n",
    "list_sentence = []\n",
    "for row in list_review_rev1:\n",
    "    list_tmp = []\n",
    "    for i, review in enumerate(row):\n",
    "        list_s = re.split(r'。|！|？', review)\n",
    "        for sen in list_s:\n",
    "            list_tmp.append([i, sen])\n",
    "    list_sentence.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 文字の前後の空白を削除\n",
    "list_sentence_rev = []\n",
    "for row in list_sentence:\n",
    "    list_tmp = []\n",
    "    for sen in row:\n",
    "        sentence = sen[1].replace(' ', '')\n",
    "        if len(sentence) > 1:\n",
    "            list_tmp.append([sen[0], sentence])\n",
    "    list_sentence_rev.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先頭が、」もしくは）で始まってる場合、前の文にくっつける\n",
    "list_sentence_rev1 = []\n",
    "for row in list_sentence_rev:\n",
    "    list_tmp = []\n",
    "    for i in range(len(row)-1):\n",
    "        if re.match(r'」|』|\\)|）', row[i][1]):\n",
    "            pass\n",
    "        elif re.match(r'」|』|\\)|）', row[i+1][1]):\n",
    "            list_tmp.append([row[i][0], row[i][1]+row[i+1][1]])\n",
    "        else:\n",
    "            list_tmp.append([row[i][0], row[i][1]])\n",
    "    else:\n",
    "        list_tmp.append([row[i+1][0], row[i+1][1]])\n",
    "        list_sentence_rev1.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Filer.writetsv(list_sentence_rev1[0], '../files/sentencefile/sentence-51637.tsv')\n",
    "Filer.writetsv(list_sentence_rev1[1], '../files/sentencefile/sentence-1238.tsv')\n",
    "Filer.writetsv(list_sentence_rev1[2], '../files/sentencefile/sentence-53171.tsv')\n",
    "Filer.writetsv(list_sentence_rev1[3], '../files/sentencefile/sentence-19191.tsv')\n",
    "Filer.writetsv(list_sentence_rev1[4], '../files/sentencefile/sentence-76887.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### sentenceごとのファイルを形態素解析済みのファイルに変更する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../files/sentencefile/sentence-76887.tsv', '../files/sentencefile/sentence-1238.tsv', '../files/sentencefile/sentence-53171.tsv', '../files/sentencefile/sentence-19191.tsv', '../files/sentencefile/sentence-51637.tsv']\n"
     ]
    }
   ],
   "source": [
    "list_path = glob.glob('../files/sentencefile/*')\n",
    "print list_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentence = [Filer.readtsv(path) for path in list_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_morpho = [[[sen[1], morpho(sen[1])] for sen in row]for row in list_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writedump(list_morpho[4], '../files/morphofile/type1/morpho-51637.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_morpho1 = [[[sen[1], morpho1(sen[1])] for sen in row] for row in list_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writedump(list_morpho1[4], '../files/morphofile/type2/morpho-51637.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高頻度語、低頻度語を数え上げて削除したファイルを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_word = [word for row in list_morpho for sen in row for word in sen[1]]\n",
    "list_word1 = [word for row in list_morpho1 for sen in row for word in sen[1]]\n",
    "dict_word_freq = collections.Counter(list_word)\n",
    "dict_word_freq1 = collections.Counter(list_word1)\n",
    "list_set_word = []\n",
    "for row in list_morpho:\n",
    "    for sen in row:\n",
    "        list_set_word.extend(list(set(sen[1])))\n",
    "        \n",
    "list_set_word1 = []\n",
    "for row in list_morpho1:\n",
    "    for sen in row:\n",
    "        list_set_word1.extend(list(set(sen[1])))\n",
    "\n",
    "dict_document_freq = collections.Counter(list_set_word)\n",
    "dict_document_freq1 = collections.Counter(list_set_word1)\n",
    "print len(list_morpho[0])+len(list_morpho[1])+len(list_morpho[2])+len(list_morpho[3])+len(list_morpho[4])\n",
    "print len(list_morpho1[0])+len(list_morpho1[1])+len(list_morpho1[2])+len(list_morpho1[3])+len(list_morpho1[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "部屋 0.166852010265\n",
      "利用 0.136783575706\n",
      "ホテル 0.100427715997\n",
      "良い 0.0860992301112\n",
      "宿泊 0.0706159110351\n",
      "満足 0.0563301967494\n",
      "便利 0.047005988024\n",
      "朝食 0.0458083832335\n",
      "よい 0.0455089820359\n",
      "広い 0.0444824636441\n"
     ]
    }
   ],
   "source": [
    "# 頻度の確認、10%切りで良さそう\n",
    "for row in sorted(dict_document_freq.items(), key=lambda x:x[1], reverse=True)[0:10]:\n",
    "    print row[0], row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 除去語の記録、10%以上、2回以下\n",
    "list_remove = []\n",
    "for row in dict_document_freq.items():\n",
    "    if row[1] >= 0.1:\n",
    "        list_remove.append(row[0])\n",
    "for row in dict_word_freq.items():\n",
    "    if row[1] <= 2:\n",
    "        list_remove.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Filer.writetxt(list_remove, '../files/preprocessedfile/dict/remove_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../files/morphofile/type1/morpho-51637.dump',\n",
       " '../files/morphofile/type1/morpho-53171.dump',\n",
       " '../files/morphofile/type1/morpho-1238.dump',\n",
       " '../files/morphofile/type1/morpho-76887.dump',\n",
       " '../files/morphofile/type1/morpho-19191.dump']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_path = glob.glob('../files/morphofile/type1/*.dump')\n",
    "list_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentence = [Filer.readdump(path) for path in list_path]\n",
    "list_sentence_rev = []\n",
    "for row in list_sentence:\n",
    "    list_tmp = []\n",
    "    for sen in row:\n",
    "        list_tmp_tmp = [word for word in sen[1] if word not in list_remove]\n",
    "        list_tmp.append([sen[0], list_tmp_tmp])\n",
    "    list_sentence_rev.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 総単語数が１以下の文を削除\n",
    "list_sentence_rev = [[sen for sen in row if len(sen[1]) >= 2] for row in list_sentence_rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writedump(list_sentence_rev[4], '../files/preprocessedfile/type11/wordlist/preprocessed-19191.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### エッジリストの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../files/preprocessedfile/type11/wordlist/preprocessed-19191.dump',\n",
       " '../files/preprocessedfile/type11/wordlist/preprocessed-76887.dump',\n",
       " '../files/preprocessedfile/type11/wordlist/preprocessed-1238.dump',\n",
       " '../files/preprocessedfile/type11/wordlist/preprocessed-51637.dump',\n",
       " '../files/preprocessedfile/type11/wordlist/preprocessed-53171.dump']"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_path = glob.glob('../files/preprocessedfile/type11/wordlist/*')\n",
    "list_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentence = [Filer.readdump(path) for path in list_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bigram\n",
    "list_bigram = []\n",
    "for row in list_sentence:\n",
    "    list_tmp = []\n",
    "    for sen in row:\n",
    "        for i in range(len(sen[1])-1):\n",
    "            list_tmp.append([sen[1][i], sen[1][i+1]])\n",
    "    list_bigram.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writetsv(list_bigram[4], '../files/preprocessedfile/type11/bigram/bigram-53171.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cor\n",
    "list_cor = []\n",
    "for row in list_sentence:\n",
    "    list_tmp = []\n",
    "    for sen in row:\n",
    "        list_tmp.extend(list(itertools.combinations(tuple(sen[1]),2)))\n",
    "    list_tmp = [list(row) for row in list_tmp]\n",
    "    list_cor.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writetsv(list_cor[4], '../files/preprocessedfile/type11/cor/cor-53171.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'b'),\n",
       " ('a', 'c'),\n",
       " ('a', 'd'),\n",
       " ('a', 'e'),\n",
       " ('b', 'c'),\n",
       " ('b', 'd'),\n",
       " ('b', 'e'),\n",
       " ('c', 'd'),\n",
       " ('c', 'e'),\n",
       " ('d', 'e')]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = ['a', 'b', 'c', 'd', 'e']\n",
    "list(itertools.combinations(tuple(seq),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PRTMによって、分類した後の文書を形態素解析する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_path = glob.glob('classifiedfile/type11/bigram/sentence/*')\n",
    "removeword = 'classifiedfile/type11/bigram/sentence/classified'\n",
    "list_name = [path.replace(removeword, '') for path in list_path]\n",
    "list_name = [name.replace('.txt', '') for name in list_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 読み込み\n",
    "list_sentence = [Filer.readtxt(path) for path in list_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 形態素解析\n",
    "list_master = []\n",
    "for row in list_sentence:\n",
    "    list_tmp = [morpho(sentence) for sentence in row]\n",
    "    list_master.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "for row, name in zip(list_master, list_name):\n",
    "    Filer.writetsv(row, './classifiedfile/type11/bigram/morpho/classified'+name+'.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# エッジリストの作成\n",
    "list_bigram = []\n",
    "for row in list_master:\n",
    "    list_tmp = []\n",
    "    for sen in row:\n",
    "        for i in range(len(sen)-1):\n",
    "            list_tmp.append([sen[i], sen[i+1]])\n",
    "    list_bigram.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "for row, name in zip(list_bigram, list_name):\n",
    "    Filer.writetsv(row, './classifiedfile/type11/bigram/bigram/classified'+name+'.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cor\n",
    "list_cor = []\n",
    "for row in list_master:\n",
    "    list_tmp = []\n",
    "    for sen in row:\n",
    "        list_tmp.extend(list(itertools.combinations(tuple(sen),2)))\n",
    "    list_tmp = [list(row) for row in list_tmp]\n",
    "    list_cor.append(list_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "for row, name in zip(list_cor, list_name):\n",
    "    Filer.writetsv(row, './classifiedfile/type11/bigram/cor/classified'+name+'.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
